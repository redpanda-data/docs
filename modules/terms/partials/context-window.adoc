=== context window
:term-name: context window
:hover-text: The maximum amount of text (measured in tokens) that an LLM can process in a single request.
:category: Agentic Data Plane

The context window determines how much information an agent can consider at once, including the system prompt, conversation history, tool outputs, and retrieved documents. Larger context windows enable more sophisticated reasoning but may increase latency and cost. Common sizes range from 8K to 200K+ tokens.

See also: glossterm:llm[], glossterm:prompt[], glossterm:ai-agent[]
