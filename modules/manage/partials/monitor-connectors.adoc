ifdef::env-kubernetes[]

You can monitor the health of your Redpanda Connectors with
metrics that are exported through a Prometheus endpoint at the default port 9404. You can use Grafana to visualize the metrics and set up alerts.

== Prerequisites

- A Kubernetes cluster. You must have `kubectl` with at least version {supported-kubernetes-version}.
+
To check if you have `kubectl` installed:
+
```bash
kubectl version --short --client
```

- https://helm.sh/docs/intro/install/[Helm^] installed with at least version {supported-helm-version}.
+
To check if you have Helm installed:
+
```bash
helm version
```

endif::[]

ifndef::env-kubernetes[]
You can monitor the health of your Redpanda managed connectors with
metrics that Redpanda exports through a Prometheus HTTPS endpoint. You
can use Grafana to visualize the metrics and set up alerts.
endif::[]

== Limitations

The connectors dashboard renders metrics that are exported by managed
connectors. However, when a connector does not create a task (for
example, an empty topic list), the dashboard will not show metrics for
that connector.

== Configure Prometheus

https://prometheus.io/[Prometheus^] is a system monitoring and alerting tool. It collects and stores metrics as time-series data identified by a metric name and key/value pairs.

ifdef::env-kubernetes[]

To configure Prometheus to monitor Redpanda metrics in Kubernetes, you can use the https://prometheus-operator.dev/[Prometheus Operator^]:

. Follow the steps to https://prometheus-operator.dev/docs/user-guides/getting-started/[deploy the Prometheus Operator^].
+
Make sure to configure the Prometheus resource to target your Pods that are running Kafka Connect:
+
.`prometheus.yaml`
[,yaml,lines=9+12]
----
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus
spec:
  serviceAccountName: prometheus
  podMonitorNamespaceSelector:
    matchLabels:
      name: <namespace>
  podMonitorSelector:
    matchLabels:
      app.kubernetes.io/name: connectors
  resources:
    requests:
      memory: 400Mi
  enableAdminAPI: false
----
+
- `podMonitorNamespaceSelector.matchLabels.name`: The namespace in which Redpanda is deployed. The Prometheus Operator looks for PodMonitor resources in this namespace.
- `podMonitorSelector.matchLabels.app.kubernetes.io/name`: The value of `fullnameOverride` in your Redpanda Helm chart. The default is `connectors`. The Redpanda Helm chart creates the PodMonitor resource with this label.

. Deploy the Redpanda Connectors subchart with monitoring enabled to deploy the PodMonitor resource:
+
[tabs]
======
Helm + Operator::
+
--
.`redpanda-cluster.yaml`
[,yaml,lines=8-12]
----
apiVersion: cluster.redpanda.com/v1alpha1
kind: Redpanda
metadata:
  name: redpanda
spec:
  chartRef: {}
  clusterSpec:
    connectors:
      enabled: true
      monitoring:
        enabled: true
        scrapeInterval: 30s
----

```bash
kubectl apply -f redpanda-cluster.yaml --namespace <namespace>
```

--
Helm::
+
--
[tabs]
====
--values::
+
.`prometheus-monitoring.yaml`
[,yaml]
----
connectors:
  enabled: true
  monitoring:
    enabled: true
    scrapeInterval: 30s
----
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
--values prometheus-monitoring.yaml --reuse-values
```

--set::
+
[,bash,lines=4-6]
----
helm upgrade --install redpanda redpanda/redpanda \
  --namespace <namespace> \
  --create-namespace \
  --set connectors.enabled=true \
  --set connectors.monitoring.enabled=true \
  --set connectors.monitoring.scrapeInterval="30s"
----

====
--
======

. Wait until all Pods are running:
+
[,bash]
----
kubectl -n <namespace> rollout status statefulset redpanda --watch
----

. Ensure that the PodMonitor was deployed:
+
[,bash]
----
kubectl get podmonitor --namespace <namespace>
----

. Ensure that you've https://prometheus-operator.dev/docs/user-guides/getting-started/#exposing-the-prometheus-service[exposed the Prometheus Service^].

. Expose the Prometheus server to your localhost:
+
[,bash]
----
kubectl port-forward svc/prometheus 9090
----

. http://localhost:9090/graph[Open Prometheus^], and verify that Prometheus is scraping metrics from your endpoints.

endif::[]

ifndef::env-kubernetes[]

NOTE: You can quickly get
https://github.com/redpanda-data/observability/tree/main/cloud[Prometheus
and Grafana running locally^], but not for production instances. For
production instances, deploy Prometheus and Grafana as a standalone or
managed service, as described below.

To configure and use Prometheus to monitor Redpanda managed connector
metrics:

. In Redpanda Cloud, go to *Overview* > *How to connect* > *Prometheus*.
Click the Copy icon for *Prometheus YAML* to copy its content into your
clipboard.
. Edit the `prometheus.yml` file in the Prometheus root folder to add
the Redpanda configuration under `scrape_configs`.
+
[,yaml]
----
scrape_configs:
- job_name: redpandaCloud
    static_configs:
    - targets:
        - ...
    metrics_path: /api/cloud/prometheus/public_metrics
    basic_auth:
    username: prometheus
    password: ...
    scheme: https
----

. Save the configuration file, and restart Prometheus to apply changes.
. Observe in Prometheus that metrics from Redpanda endpoints are
scraped.

endif::[]

== Import the Grafana dashboard

You can use https://grafana.com/oss/grafana/[Grafana^] to query,
visualize, and generate alerts for metrics. Redpanda provides a
https://github.com/redpanda-data/observability/blob/main/grafana-dashboards/Connectors.json[Grafana
dashboard for connectors^].

To create and use the Grafana dashboard to gather telemetry for your
managed connectors, import the connectors dashboard JSON file
(`Connectors.json`).

== Managed connector metrics

You can monitor the following metrics for your Redpanda managed
connectors.

=== Connector tasks

Number of tasks for a specific connector, grouped by status:

* `running` - Tasks that are healthy and running.
* `paused` - Tasks that were paused by a user request.
* `failed` - Tasks that failed during execution.

Expect only `running` and `paused` tasks. Create an alert for failed
tasks.

'''''

=== Sink connector lag

The number of records still to be processed by a connector. This metric
is emitted for sink connectors only (`last_offset` -
`current_offset`).

For newly-created connectors, the metric is high until the connector
sinks all historical data.

Expect the lag not to increase over time.

'''''

=== MM2 replication latency

Age of the last record written to the target cluster by the MirrorMaker
2 connector. This metric is emitted for each partition.

For newly-created connectors, the metric is high until the connector
processes all historical data.

Expect the latency to not increase over time.

'''''

=== Count of the records sent to target (by topic)

Count of records sent to the cluster by source connectors for each
topic.

'''''

=== Redpanda consumer latency

The Redpanda consumer fetch latency for sink connectors.

'''''

=== Redpanda producer latency

The Redpanda producer request latency for source connectors.

'''''

=== Bytes in

Bytes per second (throughput) of data from Redpanda to managed
connectors.

'''''

=== Bytes out

Bytes per second (throughput) of data from managed connectors to
Redpanda.

'''''

=== Record error rate

* `record errors` - Total number of record errors seen in connector
tasks.
* `record failures` - Total number of record failures seen in
connector tasks.
* `record skipped` - Total number of records skipped by connector
tasks.

'''''

=== Producer record rate

* `record sent` - Total number of records sent by connector producers.
* `record retry` - Total number of records sent retries by connector
producers.

'''''

=== Producer record error rate

Rate of producer errors when producing records to Redpanda.

ifdef::env-kubernetes[]

== Next steps

xref:manage:kubernetes/k-manage-connectors.adoc[].

endif::[]