Applications are often modeled around a specific business object structure. As applications change and the shape of their data changes, producer schemas and consumer schemas may no longer be compatible. You can decide how a consumer handles data from a producer that uses an older or newer schema, and reduce the chance of consumers hitting deserialization errors. 

You can configure different types of schema compatibility, which are applied to a subject when a new schema is registered. The Schema Registry supports the following compatibility types:

- `BACKWARD` (*default*) - Consumers using the new schema (for example, version 10) can read data from producers using the previous schema (for example, version 9).
- `BACKWARD_TRANSITIVE` - Consumers using the new schema (for example, version 10) can read data from producers using all previous schemas (for example, versions 1-9).
- `FORWARD` - Consumers using the previous schema (for example, version 9) can read data from producers using the new schema (for example, version 10).
- `FORWARD_TRANSITIVE` - Consumers using any previous schema (for example, versions 1-9) can read data from producers using the new schema (for example, version 10).
- `FULL` - A new schema and the previous schema (for example, versions 10 and 9) are both backward and forward compatible with each other.
- `FULL_TRANSITIVE` - Each schema is both backward and forward compatible with all registered schemas.
- `NONE` - No schema compatibility checks are done.

=== Compatibility uses and constraints

- A consumer that wants to read a topic from the beginning (for example, an AI learning process) benefits from backward compatibility. It can process the whole topic using the latest schema. This allows producers to remove fields and add attributes.
- A real-time consumer that doesn't care about historical events but wants to keep up with the latest data (for example, a typical streaming application) benefits from forward compatibility. Even if producers change the schema, the consumer can carry on. 
- Full compatibility can process historical data and future data. This is the safest option, but it limits the changes that can be done. This only allows for the addition and removal of optional fields. 

If you make changes that are not inherently backward-compatible, you may need to change compatibility settings or plan a transitional period, updating producers and consumers to use the new schema while the old one is still accepted. 

|===
| Schema format | Backward-compatible tasks | Not backward-compatible tasks

| **Avro**
| Add fields with default values 

Make fields nullable
| Remove fields 

Change data types of fields 

Change enum values 

Change field constraints 

Change record of field names

| **Protobuf**
| Add fields 

Remove fields
| Remove required fields 

Change data types of fields

| **JSON**
a| Add optional properties

Relax constraints, for example:

* Decrease a `minimum` value or increase a `maximum` value
* Decrease `minItems`, `minLength`, or `minProperties`; increase `maxItems`, `maxLength`, `maxProperties`
* Add more property types (for example, `"type": "integer"` to `"type": ["integer", "string"]`)
* Add more enum values

| Remove properties

Add required properties

Change property names and types

Tighten or add constraints
|===