[NOTE]
====
include::shared:partial$enterprise-license.adoc[]
====


ifdef::env-kubernetes[]
:tiered-storage-link: manage:kubernetes/storage/tiered-storage/k-tiered-storage.adoc
:data-archiving-link: manage:kubernetes/storage/tiered-storage/k-tiered-storage.adoc#data-archiving
endif::[]
ifndef::env-kubernetes[]
:tiered-storage-link: manage:tiered-storage.adoc
:data-archiving-link: manage:tiered-storage.adoc#data-archiving
endif::[]

A Remote Read Replica topic is a read-only topic that mirrors a topic on a different cluster. Remote Read Replicas work with both xref:{tiered-storage-link}[Tiered Storage] and xref:{data-archiving-link}[archival storage].

When a topic has object storage enabled, you can create a separate remote cluster just for consumers of this topic, and populate its topics from remote storage. A read-only topic on a remote cluster can serve any consumer, without increasing the load on the origin cluster. Use cases for Remote Read Replicas include data analytics, offline model training, and development clusters.

You can create Remote Read Replica topics in a Redpanda cluster that directly accesses data stored in object storage. Because these read-only topics access data directly from object storage instead of the topics' origin cluster, there's no impact to the performance of the cluster. Topic data can be consumed within a region of your choice, regardless of the region where it was produced.

[IMPORTANT]
====
- The Remote Read Replica cluster must run on the same version of Redpanda as the origin cluster, or just one feature release ahead of the origin cluster. For example, if the origin cluster is version 23.1, the Remote Read Replica cluster can be 23.2, but not 23.4. It cannot skip feature releases.
- When upgrading, upgrade the Remote Read Replica cluster before upgrading the origin cluster.
- When upgrading to Redpanda 23.2, metadata from object storage is not synchronized until all brokers in the cluster are upgraded. If you need to force a mixed-version cluster to sync read replicas, move partition leadership to brokers running the original version.
====

ifdef::env-kubernetes[]
helm_ref:storage.tiered.config[]
endif::[]

== Prerequisites

You need the following:

* An origin cluster with xref:{tiered-storage-link}#set-up-tiered-storage[Tiered Storage] set up. Note that multi-region buckets or containers are not supported.
* A topic on the origin cluster, which you can use as a Remote Read Replica topic on the remote cluster.
* A separate remote cluster. 
** AWS: The remote cluster must be in the same region as the origin cluster.
** GCP: The remote cluster can be in the same or a different region as the origin cluster.
** Azure: Remote read replicas are not supported. 

include::shared:partial$enterprise-license.adoc[]

To check if you already have a license key applied to your cluster:

[,bash]
----
rpk cluster license info
----

== Configure object storage for the remote cluster

You must configure access to the same object storage as the origin cluster.

ifndef::env-kubernetes[]
To set up a Remote Read Replica topic on a separate remote cluster:

. Create a remote cluster for the Remote Read Replica topic. The remote cluster can be in the same or a different region as the bucket/container.
. Run `rpk cluster config edit`, and then specify properties specific to your object storage provider (your cluster will require a restart after any changes to these properties):
+
|===
| Property | Description

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_enabled[`cloud_storage_enabled`]
| Must be set to `true` to enable object storage.

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_bucket[`cloud_storage_bucket`]
| No AWS or GCS bucket is needed for the remote cluster.

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_access_key[`cloud_storage_access_key`]
| AWS or GCS access key. +
Required for AWS and GCS authentication with access keys.

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_secret_key[`cloud_storage_secret_key`]
| AWS or GCS secret key. +
Required for AWS and GCS authentication with access keys.

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_region[`cloud_storage_region`]
| Object storage region of the remote cluster. +
Required for AWS and GCS.

|  xref:reference:properties/object-storage-properties.adoc#cloud_storage_api_endpoint[`cloud_storage_api_endpoint`]
| AWS or GCS API endpoint. +
- For AWS, this can be left blank. It's generated automatically using the region and bucket. +
- For GCS, use `storage.googleapis.com`.

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_azure_container[`cloud_storage_azure_container`]
| Azure container name. +
Required for ABS.

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_azure_storage_account[`cloud_storage_azure_storage_account`]
| Azure account name. +
Required for ABS.

| xref:reference:properties/object-storage-properties.adoc#cloud_storage_azure_shared_key[`cloud_storage_azure_shared_key`]
| Azure shared key. +
Required for ABS.
|===

WARNING: Modifying `cloud_storage_bucket` property after writing data to a bucket could cause data loss.

For a complete reference on object storage properties, see xref:reference:properties/object-storage-properties.adoc[].
endif::[]

ifdef::env-kubernetes[]
[tabs]
======
Amazon S3::
+
--

You can configure access to Amazon S3 with either an IAM role attached to the instance or with access keys.

[discrete]
=== Use IAM roles

To configure access to an S3 bucket with an IAM role:

. Configure an xref:manage:security/iam-roles.adoc#configuring-iam-roles[IAM role] with read permissions for the S3 bucket.

. Override the following required cluster properties in the Helm chart:
+
[tabs]
====
--values::
+
.`cloud-storage.yaml`
[,yaml]
----
storage:
  tiered:
    config:
      cloud_storage_enabled: true
      cloud_storage_credentials_source: aws_instance_metadata
      cloud_storage_region: <region>
      cloud_storage_bucket: "none"
----
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
--values cloud-storage.yaml
```
--set::
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --set storage.tiered.config.cloud_storage_enabled=true \
  --set storage.tiered.config.cloud_storage_credentials_source=aws_instance_metadata \
  --set storage.tiered.config.cloud_storage_region=<region> \
  --set storage.tiered.config.cloud_storage_bucket="none"
```
====
+
Replace the following placeholders:
+
- `<region>`: The region of your S3 bucket.

[discrete]
=== Use access keys

To configure access to an S3 bucket with access keys instead of an IAM role:

. Grant a user the following permissions to read objects on the bucket to be used with the cluster (or on all buckets):
+
- `GetObject`
- `ListBucket`

. Create a Secret in which to store the access key and secret key.
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: storage-secrets
  namespace: <namespace>
type: Opaque
data:
  access-key: <base64-encoded-access-key>
  secret-key: <base64-encoded-secret-key>
----
+
- Replace `<base64-encoded-access-key>` with your base64-encoded access key.
- Replace `<base64-encoded-secret-key>` with your base64-encoded secret key.
. Override the following required cluster properties in the Helm chart:
+
[tabs]
====
--values::
+
.`cloud-storage.yaml`
[,yaml]
----
storage:
  tiered:
    credentialsSecretRef:
      accessKey:
        name: storage-secrets
        key: access-key
      secretKey:
        name: storage-secrets
        key: secret-key
    config:
      cloud_storage_enabled: true
      cloud_storage_credentials_source: config_file
      cloud_storage_region: <region>
      cloud_storage_bucket: "none"
----
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
--values cloud-storage.yaml
```
--set::
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --set storage.tiered.config.cloud_storage_enabled=true \
  --set storage.tiered.credentialsSecretRef.accessKey.name=storage-secrets \
  --set storage.tiered.credentialsSecretRef.accessKey.key=access-key \
  --set storage.tiered.credentialsSecretRef.secretKey.name=storage-secrets \
  --set storage.tiered.credentialsSecretRef.secretKey.key=secret-key \
  --set storage.tiered.config.cloud_storage_credentials_source=config_file \
  --set storage.tiered.config.cloud_storage_region=<region> \
  --set storage.tiered.config.cloud_storage_bucket="none"
```
====
+
Replace `<region>` with the region of your S3 bucket.

--
Google Cloud Storage::
+
--

You can configure access to Google Cloud Storage with either an IAM role attached to the instance or with access keys.

[discrete]
=== Use IAM roles

To configure access to Google Cloud Storage with an IAM role, override the following required cluster properties in the Helm chart:

[tabs]
====
--values::
+
.`cloud-storage.yaml`
[,yaml]
----
storage:
  tiered:
    config:
      cloud_storage_enabled: true
      cloud_storage_credentials_source: gcp_instance_metadata
      cloud_storage_region: <region>
      cloud_storage_bucket: "none"
----
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
--values cloud-storage.yaml
```
--set::
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --set storage.tiered.config.cloud_storage_enabled=true \
  --set storage.tiered.config.cloud_storage_credentials_source=aws_instance_metadata \
  --set storage.tiered.config.cloud_storage_region=<region> \
  --set storage.tiered.config.cloud_storage_bucket="none"
```
====

Replace `<region>` with the region of your bucket.

[discrete]
=== Use access keys

To configure access to Google Cloud Storage with access keys instead of an IAM role:

. Create a Secret in which to store the access key and secret key.
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: storage-secrets
  namespace: <namespace>
type: Opaque
data:
  access-key: <base64-encoded-access-key>
  secret-key: <base64-encoded-secret-key>
----
+
- Replace `<base64-encoded-access-key>` with your base64-encoded access key.
- Replace `<base64-encoded-secret-key>` with your base64-encoded secret key.

. Override the following required cluster properties in the Helm chart:
+
[tabs]
====
--values::
+
.`cloud-storage.yaml`
[,yaml]
----
storage:
  tiered:
    credentialsSecretRef:
      accessKey:
        name: storage-secrets
        key: access-key
      secretKey:
        name: storage-secrets
        key: secret-key
    config:
      cloud_storage_enabled: true
      cloud_storage_credentials_source: config_file
      cloud_storage_api_endpoint: storage.googleapis.com
      cloud_storage_region: <region>
      cloud_storage_bucket: "none"
----
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
--values cloud-storage.yaml
```
--set::
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --set storage.tiered.config.cloud_storage_enabled=true \
  --set storage.tiered.credentialsSecretRef.accessKey.name=storage-secrets \
  --set storage.tiered.credentialsSecretRef.accessKey.key=access-key \
  --set storage.tiered.credentialsSecretRef.secretKey.name=storage-secrets \
  --set storage.tiered.credentialsSecretRef.secretKey.key=secret-key \
  --set storage.tiered.config.cloud_storage_credentials_source=config_file \
  --set storage.tiered.config.cloud_storage_api_endpoint=storage.googleapis.com \
  --set storage.tiered.config.cloud_storage_region=<region> \
  --set storage.tiered.config.cloud_storage_bucket="none"
```
====
+
Replace `<region>` with the region of your bucket.

--
Azure Blob Storage::
+
--

To configure access to Azure Blob Storage(ABS):

. Create a Secret in which to store the access key.
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: storage-secrets
  namespace: <namespace>
type: Opaque
data:
  access-key: <base64-encoded-access-key>
----
+
- Replace `<base64-encoded-access-key>` with your base64-encoded access key.

. Override the following required cluster properties in the Helm chart:
+
[tabs]
====
--values::
+
.`cloud-storage.yaml`
[,yaml]
----
storage:
  tiered:
    credentialsSecretRef:
      secretKey:
        configurationKey: cloud_storage_azure_shared_key
        name: storage-secrets
        key: access-key
    config:
      cloud_storage_enabled: true
      cloud_storage_azure_storage_account: <account-name>
      cloud_storage_azure_container: "none"
----
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
--values cloud-storage.yaml
```
--set::
+
```bash
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --set storage.tiered.config.cloud_storage_enabled=true \
  --set storage.tiered.credentialsSecretRef.secretKey.configurationKey=cloud_storage_azure_shared_key \
  --set storage.tiered.credentialsSecretRef.secretKey.name=storage-secrets \
  --set storage.tiered.credentialsSecretRef.secretKey.key=access-key \
  --set storage.tiered.config.cloud_storage_azure_storage_account=<account-name> \
  --set storage.tiered.config.cloud_storage_azure_container="none"
```
====

Replace `<account-name>` with the name of your Azure account.
--
======
endif::[]

== Create a Remote Read Replica topic

To create the Remote Read Replica topic, run:

```bash
rpk topic create <topic_name> -c redpanda.remote.readreplica=<bucket_name>
```

- For `<topic_name>`, use the same name as the original topic.
- For `<bucket_name>`, use the bucket/container specified in the `cloud_storage_bucket` or `cloud_storage_azure_container` properties for the origin cluster.

[NOTE]
====
* The Remote Read Replica cluster must run on the same version of Redpanda as the origin cluster, or just one feature release ahead of the origin cluster. For example, if the origin cluster is version 23.1, the Remote Read Replica cluster can be 23.2, but not 23.4. It cannot skip feature releases.
* During upgrades, upgrade the Remote Read Replica cluster before upgrading the origin cluster.
* Do not use `redpanda.remote.read` or `redpanda.remote.write` with `redpanda.remote.readreplica`. Redpanda ignores the values for remote read and remote write properties on read replica topics.
====

== Reduce lag in data availability

:config-ref: cloud_storage_segment_max_upload_interval_sec

When object storage is enabled on a topic, Redpanda copies closed log segments to the configured object store.
Log segments are closed when the value of the segment size has been reached.
A topic's object store thus lags behind the local copy by the xref:reference:tunable-properties.adoc#log_segment_size[`log_segment_size`] or,
if set, by the topic's `segment.bytes` value. To reduce this lag in the data availability for the Remote Read Replica:

* You can lower the value of `segment.bytes`. This lets Redpanda archive smaller log segments more frequently, at the cost of increasing I/O and file count.
* Redpanda Self-Managed deployments can set an idle timeout with config_ref:{config-ref},true,properties/object-storage-properties[]
to force Redpanda to periodically archive the contents of open log segments to object storage.
This is useful if a topic's write rate is low and log segments are kept open for long periods of time.
The appropriate interval may depend on your total partition count: a system with less partitions can handle a higher number of segments per partition.

include::shared:partial$suggested-reading.adoc[]

https://redpanda.com/blog/remote-read-replicas-for-distributing-work[Remote Read Replicas: Read-only topics in Tiered Storage^]



