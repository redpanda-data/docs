= Node-wise Partition Recovery
:description: Feature to recover dead nodes.

Multi-node or entire-AZ failures (especially in cloud environments) and some forms of human error may result in ‘stuck’ partitions with fewer replicas than required to make a quorum. In these scenarios, some data loss is unavoidable but admins need to recover what they can and move on.

IMPORTANT: This is a last ditch measure when all other recovery options have failed. In some cases, no remaining replicas may exist for the partitions on the dead nodes. This recovery method is used in scenarios where you are already experiencing data loss - the goal is to stop the loss of any more data.

== Prerequisites

This feature has two prerequisites for recovering partitions:

* Your cluster must have one or more `dead` nodes.
* One or more partitions on these nodes must have no majority.

Executing a node-wise partition recovery with no nodes or partitions meetings these criteria will result in Redpanda performing no action.

== Perform the recovery operation

Node-wise partition recovery is performed via the RPK command `rpk cluster partitions unsafe-recover`. This command includes an interactive prompt to confirm execution of the generated recovery plan as it is a destructive operation. When you trigger node-wise partition recovery, the partitions on the node are rebuilt in a best-effort basis. You may lose data as a result of executing this operation.

The syntax for this command is as follows:

 rpk cluster partitions unsafe-recover --from-nodes 1,3,5

The `--from-nodes` parameter accepts a comma-delineated list of dead node IDs you wish to recover the data from. The above example would perform recovery operations on nodes 1, 3, and 5. Redpanda will assess these nodes to identify which partitions lack majority. It will then create a plan to recover the impacted partitions and ask you to confirm it. You must respond `yes` to the prompt to continue with recovery.

Once the recovery operation is started, you may monitor the status of its execution via the `rpk cluster partitions balancer-status` command. The recovery operation can take some time to complete, especially when a lot of data is involved, and this command allows you to monitor progress in real-time.

== Example recovery operation
Here's an example of the recovery process in action.

----
$ rpk cluster partitions unsafe-recover --from-nodes 1
NAMESPACE  TOPIC  PARTITION  REPLICA-CORE  DEAD-NODES
kafka      bar    0          [1-1]         [1]
? Confirm recovery from these nodes? Yes
Executing recovery plan...
Successfully queued the recovery plan, you may check the status by running 'rpk cluster partitions balancer-status'

$ rpk cluster partitions balancer-status
Status:                               ready
Seconds Since Last Tick:              26
Current Reassignment Count:           0
Partitions Pending Recovery (1):      [kafka/bar/0]
----