= Shadowing
:description: Set up disaster recovery for Redpanda clusters using Shadowing for cross-region replication.
:env-linux: true
:page-categories: Management, High Availability, Disaster Recovery

[NOTE]
====
include::shared:partial$enterprise-license.adoc[]
====

Shadowing is Redpanda's enterprise-grade disaster recovery solution that establishes asynchronous, offset-preserving replication between two distinct Redpanda clusters. The replication stream ensures that the shadow cluster receives exact copies of the source cluster data, including offsets, timestamps, and cluster metadata. This creates a read-only shadow cluster that you can quickly promote to handle production traffic during a disaster.

[IMPORTANT]
====
**Experiencing an active disaster?** See xref:deploy:redpanda/manual/resilience/emergency-shadowing.adoc[Emergency Shadowing Failover] for immediate step-by-step emergency procedures.
====

Unlike traditional replication tools that re-produce messages, Shadowing copies data at the byte level, ensuring shadow topics contain identical copies of source topics with preserved offsets and timestamps.

Shadowing replicates:

* **Topic data**: All records with preserved offsets and timestamps
* **Topic configurations**: Partition counts, retention policies, and other xref:reference:properties/topic-properties.adoc[topic properties]
* **xref:develop:consume-data/consumer-offsets.adoc[Consumer group offsets]**: Enables seamless consumer resumption after failover
* **Access Control Lists (ACLs)**: User permissions and security policies
* **xref:manage:schema-reg/schema-reg-overview.adoc[Schema Registry] data**: Schema definitions and compatibility settings

== How Shadowing fits into disaster recovery

Shadowing addresses enterprise disaster recovery requirements driven by regulatory compliance and business continuity needs. Organizations typically want to minimize both recovery time objective (RTO) and recovery point objective (RPO), and Shadowing asynchronous replication helps you achieve both goals by reducing data loss during regional outages and enabling rapid application recovery.

The architecture follows an active-standby pattern. The source cluster processes all production traffic while the shadow cluster remains in read-only mode, continuously receiving updates. If a disaster occurs, you can promote the shadow topics using the Admin API or rpk, making them fully writable. At that point, you can redirect your applications to the shadow cluster, which becomes the new production cluster.

Shadowing complements Redpanda's existing availability and recovery capabilities. xref:deploy:redpanda/manual/high-availability.adoc[High availability] actively protects your day-to-day operations, handling reads and writes seamlessly during node or availability zone failures within a region. Shadowing is your insurance policy for catastrophic regional disasters.

While xref:manage:whole-cluster-restore.adoc[Whole Cluster Restore] provides point-in-time recovery from xref:manage:tiered-storage.adoc[Tiered Storage], Shadowing delivers real-time, cross-region replication for mission-critical applications that require rapid failover with minimal data loss.

// TODO: insert diagram. Possibly with a .gif animation showing cluster Cluster A being written and cluster B being replicated with a data flow arrow and geo-separation. Diagram must show Icons or labels for topics, configurations, offsets, ACLs, schemas that are being copied

== Limitations

Shadowing is designed for active-passive disaster recovery scenarios. Each shadow cluster can maintain only one shadow link.

Shadowing operates exclusively in asynchronous mode and doesn't support active-active configurations. This means there will always be some replication lag. You cannot write to both clusters simultaneously.

xref:develop:data-transforms/index.adoc[Data transforms] are disabled on shadow clusters while Shadowing is active. During a disaster, xref:manage:audit-logging.adoc[audit log] history from the source cluster is lost, though the shadow cluster begins generating new audit logs immediately after promotion.

Once you promote shadow topics after a failover, automatic fallback to the original source cluster is not supported. You cannot modify shadow topics through the Kafka API while Shadowing is active.

== Prerequisites

=== Licensing and cluster requirements

- You must have xref:get-started:licensing/overview.adoc[Enterprise Edition] licenses on both clusters. 

- Both clusters must run Redpanda version 25.3 or later. The shadow cluster can be one feature release ahead of the source cluster, but cannot skip feature releases. For example, if the source cluster runs version 25.3, the shadow cluster can run 25.3 or 26.1, but not 27.1.

[TIP]
====
Deploy clusters in different geographic regions to protect against regional disasters.
====

=== Administrative access

Superuser access is required on both clusters through xref:get-started:rpk/index.adoc[rpk], the Admin API, or xref:console:index.adoc[Redpanda Console] to create and manage shadow links.

=== Replication service permissions

You must configure a service account on the source cluster with the following xref:manage:security/authorization/acl.adoc[ACL] permissions for shadow link replication:

* **Topics**: `read` permission on all topics you want to replicate
* **Topic configurations**: `describe_configs` permission on topics for configuration synchronization
* **Consumer groups**: `describe` and `read` permission on consumer groups for offset replication
* **ACLs**: `describe` permission on ACL resources to replicate security policies
* **Cluster**: `describe` permission on the cluster resource for metadata access

This service account authenticates from the shadow cluster to the source cluster and performs the actual data replication. The credentials for this account are provided when you set up the shadow link.

=== Network and authentication

You must configure network connectivity between clusters with appropriate firewall rules to allow the shadow cluster to connect to the source cluster for data replication. Shadowing uses a pull-based architecture where the shadow cluster fetches data from the source cluster.

If using xref:manage:security/authentication.adoc[authentication] for the shadow link connection, configure the source cluster with your chosen authentication method (SASL/SCRAM, TLS, mTLS) and ensure the shadow cluster has the proper credentials to authenticate to the source cluster.

== Set up Shadowing

Setting up Shadowing involves:

* **Understanding replication behavior**: Review what topic properties, consumer groups, and security settings Redpanda automatically replicates versus what requires explicit configuration
* **Configuring filters**: Define which topics, consumer groups, and ACLs should replicate by creating include/exclude patterns that match your disaster recovery requirements
* **Creating a shadow link**: Establish the connection between clusters using rpk, the Admin API, or Redpanda Console with authentication and network settings

== What gets replicated

Shadowing replicates your topic data with complete fidelity, preserving all message records with their original offsets, timestamps, headers, and metadata. The partition structure remains identical between source and shadow clusters, ensuring applications can resume processing from the exact same position after failover.

Consumer group data flows according to your group filters, replicating offsets and membership information for matched groups. Security configurations including ACLs, user roles, and SCRAM credentials replicate based on your security filters, while Schema Registry data synchronizes schema definitions, versions, and compatibility settings.

The following topic properties are always replicated:

* `partition.count`
* `max.message.bytes`
* `cleanup.policy`
* `message.timestamp.type`

The following topic properties are never replicated:

* `redpanda.remote.readreplica`
* `redpanda.remote.recovery`
* `redpanda.remote.allowgaps`
* `redpanda.virtual.cluster.id`
* `redpanda.leaders.preference`
* `redpanda.cloud_topic.enabled`


By default, Redpanda always syncs the following topic properties:

* `compression.type`
* `retention.bytes`
* `retention.ms`
* `delete.retention.ms`
* `replication.factor`
* `min.compaction.lag.ms`
* `max.compaction.lag.ms`

Additional topic properties are replicated only when you explicitly specify them in your `synced_shadow_topic_properties` configuration. Set `exclude_default` to `true` if you want to sync only the properties listed in `synced_shadow_topic_properties`. The filtering system you configure determines the precise scope of replication across all components, allowing you to balance comprehensive disaster recovery with operational efficiency.

=== Set filters

Filters control exactly what data Shadowing replicates from your source cluster. You can define filters for topics, consumer groups, security settings, and ACLs to create a targeted disaster recovery scope rather than replicating everything.

==== Filter types and patterns

Each filter uses two key settings:

* **Pattern type**: Determines how names are matched
  - `LITERAL`: Matches names exactly (including the special wildcard `*` to match all items)
  - `PREFIX`: Matches names that start with the specified string
* **Filter type**: Specifies whether to include or exclude matching items
  - `INCLUDE`: Replicate items that match the pattern
  - `EXCLUDE`: Skip items that match the pattern

==== Filter processing rules

Redpanda processes filters in the order you define them and applies the first matching rule. Design your filter lists carefully:

1. **Order matters**: Place more specific filters before general ones
2. **First match wins**: Once a name matches a filter, subsequent filters are ignored for that item
3. **Default behavior**: Items that don't match any filter are excluded from replication

==== Common filtering patterns

**Replicate all topics except test topics:**
[,yaml]
----
auto_create_shadow_topic_filters:
  - pattern_type: "PREFIX"
    filter_type: "EXCLUDE" 
    name: "test-"
  - pattern_type: "LITERAL"
    filter_type: "INCLUDE"
    name: "*"
----

**Replicate only production topics:**
[,yaml]
----
auto_create_shadow_topic_filters:
  - pattern_type: "PREFIX"
    filter_type: "INCLUDE"
    name: "prod-"
  - pattern_type: "PREFIX" 
    filter_type: "INCLUDE"
    name: "production-"
----

**Replicate specific consumer groups:**
[,yaml]
----
group_filters:
  - pattern_type: "LITERAL"
    filter_type: "INCLUDE"
    name: "critical-app-consumers"
  - pattern_type: "PREFIX"
    filter_type: "INCLUDE" 
    name: "prod-consumer-"
----

==== System topic filtering rules

Redpanda system topics have specific filtering restrictions:

* Literal filters for `__consumer_offsets` and `_redpanda.audit_log` are rejected
* Prefix filters for topics starting with `_redpanda` or `__redpanda` are rejected  
* Wildcard `*` filters will not match topics that start with `_redpanda` or `__redpanda`
* To shadow specific system topics, you must provide explicit literal filters for those individual topics

==== ACL filtering

ACL filters are more complex as they filter based on both resource and access properties:

[,yaml]
----
acl_filters:
  # Include read permissions for production topics
  - resource_filter:
      resource_type: "TOPIC"
      pattern_type: "PREFIX"
      name: "prod-"
    access_filter:
      principal: "User:app-user"
      operation: "READ"
      permission_type: "ALLOW" 
      host: "*"
  # Include consumer group permissions
  - resource_filter:
      resource_type: "GROUP"
      pattern_type: "LITERAL"
      name: "*"
    access_filter:
      principal: "User:app-user" 
      operation: "READ"
      permission_type: "ALLOW"
      host: "*"
----

==== Generate a sample configuration

Use rpk to generate a sample configuration file with common filter patterns:

[,bash]
----
rpk shadow config generate --output shadow-link-config.yaml
----

This creates a template configuration file that you can customize for your environment.

=== Networking

Configure network connectivity between your source and shadow clusters to enable shadow link replication. The shadow cluster initiates connections to the source cluster using a pull-based architecture.

==== Connection requirements

* **Direction**: Shadow cluster connects to source cluster (outbound from shadow, inbound to source)
* **Protocol**: Kafka protocol over TCP (default port 9092, or your configured listener ports)
* **Persistence**: Connections remain active for continuous replication

==== Firewall configuration

Configure firewall rules to allow the shadow cluster to reach the source cluster:

**On the source cluster network:**
* Allow inbound TCP connections on Kafka listener ports (typically 9092)
* Allow connections from the shadow cluster's IP addresses or subnets

**On the shadow cluster network:**  
* Allow outbound TCP connections to the source cluster's Kafka listener ports
* Ensure DNS resolution works for source cluster hostnames

==== Bootstrap servers

Specify multiple bootstrap servers in your shadow link configuration for high availability:

[,yaml]
----
client_options:
  bootstrap_servers:
    - "source-broker-1.example.com:9092"
    - "source-broker-2.example.com:9092" 
    - "source-broker-3.example.com:9092"
----

The shadow cluster uses these addresses to discover all brokers in the source cluster. If one bootstrap server is unavailable, the shadow cluster tries the next one in the list.

==== Network security

For production deployments, secure the network connection between clusters:

**TLS encryption:**
[,yaml]
----
client_options:
  tls_settings:
    ca_path: "/path/to/ca.crt"
    # Optional client certificates for mTLS
    key_path: "/path/to/client.key" 
    cert_path: "/path/to/client.crt"
----

**Authentication:**
[,yaml]
----
client_options:
  authentication_configuration:
    username: "shadow-replication-user"
    password: "secure-password"
    scram_mechanism: "SCRAM-SHA-256"
----

==== Connection tuning

Adjust connection parameters based on your network characteristics:

[,yaml]
----
client_options:
  connection_timeout_ms: 1000      # Default 1000ms, increase for high-latency networks
  retry_backoff_ms: 100            # Default 100ms, backoff between connection retries  
  metadata_max_age_ms: 10000       # Default 10000ms, how often to refresh cluster metadata
----

=== Create a shadow link

You can establish a shadow link using either xref:get-started:rpk/index.adoc[rpk], the Admin API, or xref:console:index.adoc[Redpanda Console]. Run the following rpk command from the shadow cluster to create a shadow link with the source cluster:

[,bash]
----
rpk shadow create --config-file /path/to/shadow-config.yaml
----

[TIP]
====
Use xref:get-started:config-rpk-profile.adoc[`rpk profile`] to save your cluster connection details and credentials for both source and shadow clusters, allowing you to easily switch between the two configurations.
====

==== Sample configuration file

[%collapsible]
====
[,yaml]
----
# Sample ShadowLinkConfig YAML with all fields
name: "<SHADOW_LINK_NAME>"              # Unique name for this shadow link, example: "production-dr"
client_options:
  bootstrap_servers:                     # Source cluster brokers to connect to
    - "<SOURCE_BROKER_1>:<PORT>"         # Example: "prod-kafka-1.example.com:9092"
    - "<SOURCE_BROKER_2>:<PORT>"         # Example: "prod-kafka-2.example.com:9092"
    - "<SOURCE_BROKER_3>:<PORT>"         # Example: "prod-kafka-3.example.com:9092"
  source_cluster_id: "<CLUSTER_ID>"      # Optional: Expected source cluster ID for validation, example: "prod-cluster-123"
  
  # TLS settings using file paths
  tls_settings:
    ca_path: "<CA_CERT_PATH>"            # Path to CA certificate, example: "/etc/ssl/certs/ca.crt"
    key_path: "<CLIENT_KEY_PATH>"        # Optional: Path to client private key, example: "/etc/ssl/private/client.key"
    cert_path: "<CLIENT_CERT_PATH>"      # Optional: Path to client certificate, example: "/etc/ssl/certs/client.crt"
  
  # Alternative TLS settings using PEM content
  # tls_settings:
  #   ca: |                              # CA certificate in PEM format
  #     -----BEGIN CERTIFICATE-----
  #     ... CA certificate content ...
  #     -----END CERTIFICATE-----
  #   key: |                             # Client private key in PEM format
  #     -----BEGIN PRIVATE KEY-----
  #     ... private key content ...
  #     -----END PRIVATE KEY-----
  #   cert: |                            # Client certificate in PEM format
  #     -----BEGIN CERTIFICATE-----
  #     ... client certificate content ...
  #     -----END CERTIFICATE-----
  
  authentication_configuration:
    username: "<SASL_USERNAME>"          # SASL/SCRAM username, example: "shadow-replication-user"
    password: "<SASL_PASSWORD>"          # SASL/SCRAM password, example: "secure-password-123"
    scram_mechanism: "SCRAM-SHA-256"     # SCRAM mechanism: "SCRAM-SHA-256" or "SCRAM-SHA-512"
  
  # Connection tuning - adjust based on network characteristics
  metadata_max_age_ms: 10000             # How often to refresh cluster metadata (default: 10000ms)
  connection_timeout_ms: 1000            # Connection timeout (default: 1000ms, increase for high latency)
  retry_backoff_ms: 100                  # Backoff between retries (default: 100ms)
  fetch_wait_max_ms: 100                 # Max time to wait for fetch requests (default: 100ms)
  fetch_min_bytes: 1                     # Min bytes per fetch (default: 1)
  fetch_max_bytes: 1048576               # Max bytes per fetch (default: 1MB)

topic_metadata_sync_options:
  interval: "30s"                        # How often to sync topic metadata (examples: "30s", "1m", "5m")
  auto_create_shadow_topic_filters:      # Filters for automatic topic creation
    - pattern_type: "PREFIX"             # Match topics starting with this prefix
      filter_type: "INCLUDE"
      name: "<TOPIC_PREFIX>"             # Examples: "prod-", "production-", "app-"
    - pattern_type: "LITERAL"            # Exclude specific topics
      filter_type: "EXCLUDE"
      name: "<EXCLUDED_TOPIC>"           # Examples: "temp-data", "test-topic"
    - pattern_type: "LITERAL"            # Include all remaining topics (wildcard)
      filter_type: "INCLUDE"
      name: "*"
  synced_shadow_topic_properties:        # Additional topic properties to sync (beyond defaults)
    - "retention.ms"                     # Topic retention time
    - "segment.ms"                       # Segment roll time
    - "<CUSTOM_PROPERTY>"                # Examples: "compression.type", "min.insync.replicas"

consumer_offset_sync_options:
  interval: "30s"                        # How often to sync consumer group offsets
  enabled: true                          # Enable consumer offset synchronization
  group_filters:                         # Filters for consumer groups to sync
    - pattern_type: "PREFIX"
      filter_type: "INCLUDE"
      name: "<CONSUMER_GROUP_PREFIX>"    # Examples: "prod-consumer-", "app-"
    - pattern_type: "LITERAL"
      filter_type: "EXCLUDE"
      name: "<EXCLUDED_GROUP>"           # Examples: "test-consumer", "debug-group"

security_sync_options:
  interval: "30s"                        # How often to sync security settings
  enabled: true                          # Enable security settings synchronization
  role_filters:                          # Filters for user roles to sync
    - pattern_type: "LITERAL"
      filter_type: "INCLUDE"
      name: "<ROLE_NAME>"                # Examples: "application-user", "read-only"
  scram_cred_filters:                    # Filters for SCRAM credentials to sync
    - pattern_type: "PREFIX"
      filter_type: "EXCLUDE"
      name: "<ADMIN_PREFIX>"             # Examples: "admin-", "root-"
  acl_filters:                           # Filters for ACLs to sync
    - resource_filter:
        resource_type: "TOPIC"           # Resource type: "TOPIC", "GROUP", "CLUSTER"
        pattern_type: "PREFIX"           # Pattern type: "LITERAL", "PREFIX", "PREFIXED"
        name: "<RESOURCE_PATTERN>"       # Examples: "prod-", "app-data-"
      access_filter:
        principal: "User:<USERNAME>"     # Principal name, example: "User:app-service"
        operation: "READ"                # Operation: "READ", "WRITE", "CREATE", "DELETE", "ALTER", "DESCRIBE", "ANY"
        permission_type: "ALLOW"         # Permission: "ALLOW" or "DENY"
        host: "<HOST_PATTERN>"           # Host pattern, examples: "*", "10.0.0.0/8", "app-server.example.com"
----
====

For the complete reference, see link:/api/doc/admin/[Admin API v2 reference^].

== Failover

// TODO: explain what failover is, how do we activate it per topic and per cluster

== Monitoring and troubleshooting

List existing shadow links:

[,bash]
----
rpk shadow list
----

Check your shadow link status to ensure proper operation:

[,bash]
----
rpk shadow status <my-disaster-recovery-link>
----

This displays replication lag, connection health, and the status of individual synchronization tasks.

// TODO: expand on status/describe

=== Metrics

Shadowing provides several metrics to track replication performance and health:

// TODO: Update the new metric names 

* `redpanda_panda_link_mirror_lag` - Measures replication lag between source and shadow clusters
* `redpanda_panda_link_total_bytes_fetched` - Total bytes retrieved from the source cluster
* `redpanda_panda_link_total_bytes_written` - Total bytes written to the shadow cluster
* `redpanda_panda_link_total_records_fetched` - Number of records retrieved from source
* `redpanda_panda_link_total_records_written` - Number of records written to shadow
* `redpanda_panda_link_client_quota_throttle_time` - Time spent throttled due to quota limits
* `redpanda_panda_link_client_errors` - Count of client connection errors
* `redpanda_panda_link_partition_mirrors_state` - State of individual partition mirrors

For complete metrics reference, see xref:reference:public-metrics-reference.adoc[].
