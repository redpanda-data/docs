= Deploy a Local Development Cluster with kind or minikube
:description: Deploy a local Redpanda cluster with Redpanda Console using the Helm chart.
:page-aliases: getting-started:kubernetes-qs-local-access.adoc, quickstart:kubernetes-qs-local-access.adoc, quickstart:kubernetes-qs-minikube.adoc, getting-started:kubernetes-qs-minikube.adoc
:env-kubernetes: true
:page-categories: Deployment

Deploy a local Redpanda cluster with Redpanda Console using the Helm chart. Explore the essentials of how Redpanda works in Kubernetes and what components are deployed by default. Then, use `rpk` both as an internal client and an external client to interact with your Redpanda cluster from the command line.

.Only for development and testing
[CAUTION]
====
Do not use kind or minikube for production workloads. Instead, try one of the following environments:

* xref:./aks-guide.adoc[Azure Kubernetes Service] (AKS)
* xref:./eks-guide.adoc[Elastic Kubernetes Service] (EKS)
* xref:./gke-guide.adoc[Google Kubernetes Engine] (GKE)
====

== Prerequisites

Before you begin, make sure that you have the correct software for your Kubernetes platform:

[tabs]
======
kind::
+
--

* https://kubernetes.io/docs/tasks/tools/[Install `kubectl`^]. Minimum required Kubernetes version: {supported-kubernetes-version}
+
```bash
kubectl version --client
```

* https://helm.sh/docs/intro/install/[Install Helm^]. Minimum required Helm version: {supported-helm-version}
+
```bash
helm version
```

* https://kind.sigs.k8s.io/docs/user/quick-start/#installation[Install kind^]

* https://docs.docker.com/get-docker/[Install Docker^]

--
minikube::
+
--

* https://kubernetes.io/docs/tasks/tools/[Install `kubectl`^]. Minimum required Kubernetes version: {supported-kubernetes-version}
+
```bash
kubectl version --short --client
```

* https://helm.sh/docs/intro/install/[Install Helm^]. Minimum required Helm version: {supported-helm-version}
+
```bash
helm version
```

* https://minikube.sigs.k8s.io/docs/start/[Install minikube^]

--
======

== Create a Kubernetes cluster

In this step, you create one master and three worker nodes (one worker node for each Redpanda broker).

[tabs]
======
kind::
+
--

. Define a cluster in the `kind.yaml` configuration file:
+
```bash
cat <<EOF >kind.yaml
---
apiVersion: kind.x-k8s.io/v1alpha4
kind: Cluster
nodes:
  - role: control-plane
  - role: worker
  - role: worker
  - role: worker
EOF
```

. Create the Kubernetes cluster from the configuration file:
+
```bash
kind create cluster --config kind.yaml
```

--
minikube::
+
--

. Create the Kubernetes cluster:
+
```bash
minikube start --namespace redpanda --nodes 4
```

. Prevent applications from being scheduled on the Kubernetes control plane node:
+
```bash
kubectl taint node \
  -l node-role.kubernetes.io/control-plane="" \
    node-role.kubernetes.io/control-plane=:NoSchedule
```
--
======

NOTE: The Helm chart configures default `podAntiAffinity` rules to make sure that only one Pod running a Redpanda broker is scheduled on each worker node. To learn why, see xref:deploy:deployment-option/self-hosted/kubernetes/k-requirements.adoc#number-of-workers[Number of workers].


== Deploy Redpanda and Redpanda Console

In this step, you deploy Redpanda with self-signed TLS certificates. Redpanda Console is included as a subchart in the Redpanda Helm chart.

[tabs]
======
Helm + Operator::
+
--

. Make sure that you have permission to install custom resource definitions (CRDs):
+
```bash
kubectl auth can-i create CustomResourceDefinition --all-namespaces
```
+
You should see `yes` in the output.
+
You need these cluster-level permissions to install glossterm:cert-manager[] and Redpanda Operator CRDs in the next steps.

. Install https://cert-manager.io/docs/installation/helm/[cert-manager^] using Helm:
+
```bash
helm repo add jetstack https://charts.jetstack.io
helm repo update
helm install cert-manager jetstack/cert-manager --set crds.enabled=true --namespace cert-manager --create-namespace
```
+
TLS is enabled by default. The Redpanda Helm chart uses cert-manager to manage TLS certificates by default.

. Install the Redpanda Operator custom resource definitions (CRDs):
+
include::deploy:partial$kubernetes/install-crds.adoc[]

. Deploy the Redpanda Operator:
+
[,bash,subs="attributes+"]
----
helm repo add redpanda https://charts.redpanda.com
helm repo update redpanda
helm upgrade --install redpanda-controller redpanda/operator \
  --namespace <namespace> \
  --set image.tag={latest-operator-version} \
  --create-namespace
----

. Ensure that the Deployment is successfully rolled out:
+
```bash
kubectl --namespace <namespace> rollout status --watch deployment/redpanda-controller-operator
```
+
[.no-copy]
----
deployment "redpanda-controller-operator" successfully rolled out
----

. Install a xref:reference:k-crd.adoc[Redpanda custom resource] in the same namespace as the Redpanda Operator:
+
.`redpanda-cluster.yaml`
[,yaml,subs="attributes+"]
----
apiVersion: cluster.redpanda.com/v1alpha2
kind: Redpanda
metadata:
  name: redpanda
spec:
  chartRef:
    chartVersion: {latest-redpanda-helm-chart-version}
  clusterSpec:
    external:
      domain: customredpandadomain.local
    statefulset:
      initContainers:
        setDataDirOwnership:
          enabled: true
----
+
```bash
kubectl apply -f redpanda-cluster.yaml --namespace <namespace>
```

. Wait for the Redpanda Operator to deploy Redpanda using the Helm chart:
+
```bash
kubectl get redpanda --namespace <namespace> --watch
```
+
[.no-copy]
----
NAME       READY   STATUS
redpanda   True    Redpanda reconciliation succeeded
----
+
This step may take a few minutes. You can watch for new Pods to make sure that the deployment is progressing:
+
```bash
kubectl get pod --namespace <namespace>
```
+
If it's taking too long, see <<Troubleshoot>>.
--

Helm::
+
--

. Add the Redpanda Helm chart repository and install cert-manager using Helm:
+
```bash
helm repo add redpanda https://charts.redpanda.com
helm repo add jetstack https://charts.jetstack.io
helm repo update
helm install cert-manager jetstack/cert-manager  --set crds.enabled=true --namespace cert-manager  --create-namespace
```
+
The Redpanda Helm chart uses cert-manager to manage TLS certificates.

. Install Redpanda using Helm:
+
[source,bash,subs="attributes+"]
----
helm repo add redpanda https://charts.redpanda.com/
helm repo update
helm install redpanda redpanda/redpanda \
  --version {latest-redpanda-helm-chart-version} \
  --namespace <namespace> \
  --create-namespace \
  --set external.domain=customredpandadomain.local \
  --set statefulset.initContainers.setDataDirOwnership.enabled=true
----
+
The installation displays some tips for getting started.

. Wait for the Redpanda cluster to be ready:
+
```bash
kubectl --namespace <namespace> rollout status statefulset redpanda --watch
```
+
When the Redpanda cluster is ready, the output should look similar to the following:
+
[,plain,no-copy]
----
statefulset rolling update complete 3 pods at revision redpanda-8654f645b4...
----
+
If your cluster remains in a pending state, see <<Troubleshoot>>.

--
======

== Start streaming

Each Redpanda broker comes with `rpk`, which is a CLI tool for connecting to and interacting with Redpanda brokers. You can use `rpk` inside one of the Redpanda broker's Docker containers to create a topic, produce messages to it, and consume messages from it.

. Create an alias to simplify the `rpk` commands:
+
```bash
alias internal-rpk="kubectl --namespace <namespace> exec -i -t redpanda-0 -c redpanda -- rpk"
```

. Create a topic called `twitch-chat`:
+
[tabs]
======
Helm + Operator::
+
--

.. Create a xref:manage:kubernetes/k-manage-topics.adoc[Topic resource]:
+
.`topic.yaml`
[,yaml]
----
apiVersion: cluster.redpanda.com/v1alpha2
kind: Topic
metadata:
  name: twitch-chat
spec:
  kafkaApiSpec:
    brokers:
      - "redpanda-0.redpanda.<namespace>.svc.cluster.local:9093"
      - "redpanda-1.redpanda.<namespace>.svc.cluster.local:9093"
      - "redpanda-2.redpanda.<namespace>.svc.cluster.local:9093"
    tls:
      caCertSecretRef:
        name: "redpanda-default-cert"
        key: "ca.crt"
----

.. Apply the Topic resource in the same namespace as your Redpanda cluster:
+
[,bash]
----
kubectl apply -f topic.yaml --namespace <namespace>
----

.. Check the logs of the Redpanda Operator to confirm that the topic was created:
+
[,bash]
----
kubectl logs -l app.kubernetes.io/name=operator -c manager --namespace <namespace>
----
+
You should see that the Redpanda Operator reconciled the Topic resource.
+
.Example output
[%collapsible]
====
[,json,.no-copy,lines=5+22]
----
{
  "level":"info",
  "ts":"2023-09-25T16:20:09.538Z",
  "logger":"TopicReconciler.Reconcile",
  "msg":"Starting reconcile loop",
  "controller":"topic",
  "controllerGroup":"cluster.redpanda.com",
  "controllerKind":"Topic",
  "Topic":
  {
    "name":"twitch-chat",
    "namespace":"<namespace>"
  },
  "namespace":"<namespace>",
  "name":"twitch-chat",
  "reconcileID":"c0cf9abc-a553-48b7-9b6e-2de3cdfb4432"
}
{
  "level":"info",
  "ts":"2023-09-25T16:20:09.581Z",
  "logger":"TopicReconciler.Reconcile",
  "msg":"reconciliation finished in 43.436125ms, next run in 3s",
  "controller":"topic",
  "controllerGroup":"cluster.redpanda.com",
  "controllerKind":"Topic",
  "Topic":
  {
    "name":"twitch-chat",
    "namespace":"<namespace>"
  },
  "namespace":"<namespace>",
  "name":"twitch-chat",
  "reconcileID":"c0cf9abc-a553-48b7-9b6e-2de3cdfb4432",
  "result":
  {
    "Requeue":false,
    "RequeueAfter":3000000000
  }
}
----
====

--
Helm::
+
--

[,bash]
----
internal-rpk topic create twitch-chat
----

Example output:

[.no-copy]
----
TOPIC STATUS twitch-chat OK
----

--
======

. Describe the topic:
+
```bash
internal-rpk topic describe twitch-chat
```
+
.Expected output:
[%collapsible]
====
[.no-copy]
```
SUMMARY
=======
NAME        twitch-chat
PARTITIONS  1
REPLICAS    1

CONFIGS
=======
KEY                     VALUE                          SOURCE
cleanup.policy          delete                         DYNAMIC_TOPIC_CONFIG
compression.type        producer                       DEFAULT_CONFIG
message.timestamp.type  CreateTime                     DEFAULT_CONFIG
partition_count         1                              DYNAMIC_TOPIC_CONFIG
redpanda.datapolicy     function_name:  script_name:   DEFAULT_CONFIG
redpanda.remote.read    false                          DEFAULT_CONFIG
redpanda.remote.write   false                          DEFAULT_CONFIG
replication_factor      1                              DYNAMIC_TOPIC_CONFIG
retention.bytes         -1                             DEFAULT_CONFIG
retention.ms            604800000                      DEFAULT_CONFIG
segment.bytes           1073741824                     DEFAULT_CONFIG
```
====

. Produce a message to the topic:
+
```bash
internal-rpk topic produce twitch-chat
```

. Type a message, then press kbd:[Enter]:
+
```text
Pandas are fabulous!
```
+
Example output:
+
```text
Produced to partition 0 at offset 0 with timestamp 1663282629789.
```

. Press kbd:[Ctrl + C] to finish producing messages to the topic.

. Consume one message from the topic:
+
```bash
internal-rpk topic consume twitch-chat --num 1
```
+
.Expected output:
[%collapsible]
====
[.no-copy]
Your message is displayed along with its metadata:
```json
  {
    "topic": "twitch-chat",
    "value": "Pandas are fabulous!",
    "timestamp": 1663282629789,
    "partition": 0,
    "offset": 0
  }
```
====


include::deploy:partial$kubernetes/guides/explore-topics-localhost.adoc[leveloffset=+1]

include::deploy:partial$kubernetes/guides/external-access-intro.adoc[leveloffset=+1]

NOTE: These steps work only on Linux operating systems.

. Add mappings in your `/etc/hosts` file between your worker nodes' IP addresses and their custom domain names:
+
```bash
sudo true && kubectl --namespace <namespace> get endpoints,node -A -o go-template='{{ range $_ := .items }}{{ if and (eq .kind "Endpoints") (eq .metadata.name "redpanda-external") }}{{ range $_ := (index .subsets 0).addresses }}{{ $nodeName := .nodeName }}{{ $podName := .targetRef.name }}{{ range $node := $.items }}{{ if and (eq .kind "Node") (eq .metadata.name $nodeName) }}{{ range $_ := .status.addresses }}{{ if eq .type "InternalIP" }}{{ .address }} {{ $podName }}.customredpandadomain.local{{ "\n" }}{{ end }}{{ end }}{{ end }}{{ end }}{{ end }}{{ end }}{{ end }}' | envsubst | sudo tee -a /etc/hosts
```
+
.`/etc/hosts`
----
203.0.113.3 redpanda-0.customredpandadomain.local
203.0.113.5 redpanda-1.customredpandadomain.local
203.0.113.7 redpanda-2.customredpandadomain.local
----

. Save the root certificate authority (CA) to your local file system outside Kubernetes:
+
[,bash]
----
kubectl --namespace <namespace> get secret redpanda-external-root-certificate -o go-template='{{ index .data "ca.crt" | base64decode }}' > ca.crt
----

. Install `rpk` on your local Linux machine, not on a Pod:
+
--
[loweralpha]
include::get-started:partial$install-rpk-linux.adoc[tags=latest]
--

. Configure `rpk` to connect to your cluster using the xref:manage:kubernetes/networking/k-connect-to-redpanda.adoc#rpk-profile[pre-configured profile]:
+
[source,bash]
----
rpk profile create --from-profile <(kubectl get configmap --namespace <namespace> redpanda-rpk -o go-template='{{ .data.profile }}') <profile-name>
----
+
Replace `<profile-name>` with the name that you want to give this `rpk` profile.

. Test the connection:
+
```bash
rpk cluster info
```

include::deploy:partial$kubernetes/default-components.adoc[leveloffset=+1]

include::deploy:partial$kubernetes/guides/uninstall.adoc[leveloffset=+1]

== Delete the cluster

To delete your Kubernetes cluster:

[tabs]
======
kind::
+
--

[,bash]
----
kind delete cluster
----

--
minikube::
+
--
[,bash]
----
minikube delete
----
--
======


include::deploy:partial$kubernetes/guides/troubleshoot.adoc[leveloffset=+1]

include::deploy:partial$kubernetes/guides/next-steps.adoc[leveloffset=+1]

include::shared:partial$suggested-reading.adoc[]

include::deploy:partial$kubernetes/guides/suggested-reading-content.adoc[leveloffset=+1]
