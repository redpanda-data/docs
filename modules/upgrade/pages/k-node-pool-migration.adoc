= Node Pool Migration on Nodes Running Redpanda
:description: Learn how to safely migrate your Redpanda cluster to a new node pool while maintaining high availability and data integrity.
:page-categories: Management, Upgrades
:env-kubernetes: true

This topic outlines a safe procedure for migrating your Redpanda cluster to a new node pool. This is especially useful when you need to change node instance types or perform vertical scaling. The process ensures that your cluster remains fault tolerant and data safe throughout the migration.

== Prerequisites

* A staging environment for testing the migration process.
* Familiarity with your hosting platform (GKE, EKS, AKS, or self-managed) and its CLI tools (for example, `gcloud` or `eksctl`).
* Confirmation that your new node pool configuration is compatible with xref:deploy:deployment-option/self-hosted/kubernetes/k-requirements.adoc[Redpanda requirements].
* A backup of your Redpanda data in case of unexpected data loss.

== Choose your storage strategy

When migrating to new nodes, Kubernetes replaces each node's underlying virtual machine. This process impacts the Pods running on those nodes. Choose the strategy that best suits your storage backend:

* <<networked-pv, Networked (remountable) PersistentVolumes>>: For example, EBS on AWS, Persistent Disks on GCP, or Azure Disks.
* <<local-pv, Ephemeral local storage>>: For example, local PersistentVolumes, `hostPath`, or `emptyDir`.

[[networked-pv]]
=== Networked (remountable) PersistentVolumes

When using network-backed PersistentVolumes (PVs), the data is stored on external storage systems such as EBS, Persistent Disks, or Azure Disks. Because the storage remains intact even if the node is replaced, the same Pod can be rescheduled on another node and the PV will be automatically remounted.

. Confirm that a safe Pod Disruption Budget (PDB) exists:
+
[source,bash]
----
kubectl get pdb --namespace <namespace>
----
+
Setting `statefulset.budget.maxUnavailable`  to 1 in your Redpanda resource or Helm values ensures that only one broker Pod can be unavailable during the upgrade process. This setting helps maintain cluster availability and data integrity by preventing multiple Pods from being disrupted simultaneously.
+
Example output:
+
[.no-copy]
----
NAME       MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
redpanda   N/A             1                 1                     2m36s
----

. Ensure each topic has a replication factor of at least 3:
+
[source,bash]
----
rpk topic describe <topic-name>
rpk topic alter-config <topic-name> --set replication.factor=<replication-factor>
----
+
A replication factor of 3 is recommended to ensure high availability and fault tolerance. With three replicas, the system can tolerate the failure of one broker without losing data or availability. This setup allows for one replica to be down for maintenance or due to failure, while still having two replicas available to serve read and write requests. This redundancy is crucial for maintaining the health and reliability of the cluster.

. Create a new node pool with the same number of nodes as your current pool.
+
If you only have 3 brokers, add an extra one (buffer broker).
+
:note-caption: Why add an extra node?
[NOTE]
====
The recommended topic replication factor is 3. This means each partition within a topic must have three replicas to maintain cluster health. To avoid making your cluster unhealthy, add a temporary broker before upgrading any of the three original nodes. This temporary broker is not needed if you have more brokers than your highest topic replication factor.
====
:note-caption: Note

. Configure tolerations, taints, and node selectors:
+
When updating your Redpanda resource or Helm values, you need to configure tolerations and node selectors so that the Pods are scheduled onto nodes in your new node pool. Below are the steps to determine the proper values for these settings and how to apply them.
+
--
.. Identify taints on your nodes
+
Taints prevent Pods from being scheduled on a node unless they have a matching toleration. To view the taints on a node, run:
+
[,bash]
----
kubectl describe node <node-name>
----
+
In the output, look for a section similar to:
+
[.no-copy]
----
Taints: redpanda-pool-new=true:NoSchedule
----
+
Here, the taint key is `redpanda-pool-new` and the effect is `NoSchedule`.

.. Identify or set node labels
+
Node selectors use labels to target specific nodes. List the labels on your nodes with:
+
[source,bash]
----
kubectl get nodes --show-labels
----
+
If your new node pool does not already have a specific label, add one by running:
+
[source,bash]
----
kubectl label nodes <node-name> nodetype=redpanda-pool-new
----
+
Now, the label `nodetype=redpanda-pool-new` can be used as the selector.

.. Update Your Redpanda resource or Helm values.
+
Replace the placeholders in the configuration with your actual values. For example:
+
[tabs]
======
Helm + Operator::
+
Patch your Redpanda resource with the following command:
+
[source,bash]
----
cat <<EOF > patch-nodepool.yaml
spec:
  clusterSpec:
    tolerations:
      - effect: NoSchedule
        key: <taint>   # Replace <taint> with your node taint key
        operator: Equal
        value: "true"
    nodeSelector:
      nodetype: <label>   # Replace <label> with your node label value
    #statefulset:
      #replicas: 4
EOF
kubectl patch redpanda redpanda -n <namespace> --type merge --patch-file patch-nodepool.yaml
----
+
NOTE: If you created a buffer node, uncomment the `statefulset.replicas` lines to add a buffer broker to your cluster.

Helm::
+
Update your Helm values file with the following settings:
+
.`tolerations.yaml`
[source,yaml]
----
tolerations:
  - effect: NoSchedule
    key: <taint>   # Replace <taint> with your node taint key
    operator: Equal
    value: "true"
nodeSelector:
  nodetype: <label>   # Replace <label> with your node label value
#statefulset:
  #replicas: 4
----
+
NOTE: If you created a buffer node, uncomment the `statefulset.replicas` lines to add a buffer broker to your cluster.
+
Then run:
+
[source,bash]
----
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --values tolerations.yaml --reuse-values
----
======
--

. For each broker running on the old node pool, perform a rolling restart by deleting the Pod. Because the underlying networked PV is remountable, the data remains intact and the Pod will be rescheduled on the new node pool with the same broker ID.
+
[source,bash]
----
kubectl get pods --namespace <namespace>
kubectl delete pod <pod-name> --namespace <namespace> --wait=false
----

. Verify that the new broker Pods are scheduled on the new node pool:
+
[source,bash]
----
kubectl get pods --namespace <namespace> -o wide | grep <pod-name>
----

. Verify cluster health:
+
[source,bash]
----
rpk cluster health
----
+
Ensure that all brokers are online and data replication is healthy.

. Delete the old node pool following your hosting platform's best practices.

[[local-pv]]
=== Ephemeral local storage (local PV, hostPath, or emptyDir)

When using ephemeral local storage, the broker Pod's storage is tied to the Pod's lifecycle. This means the data is lost when the Pod is terminated. To preserve data integrity, you must decommission the broker so that its data and replicas are migrated, and a new broker ID is allocated when the Pod is rescheduled.

. Confirm that a safe Pod Disruption Budget (PDB) exists:
+
[source,bash]
----
kubectl get pdb --namespace <namespace>
----
+
Setting `statefulset.budget.maxUnavailable`  to 1 in your Redpanda resource or Helm values ensures that only one broker Pod can be unavailable during the upgrade process. This setting helps maintain cluster availability and data integrity by preventing multiple Pods from being disrupted simultaneously.
+
Example output:
+
[.no-copy]
----
NAME       MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
redpanda   N/A             1                 1                     2m36s
----

. Ensure each topic has a replication factor of at least 3:
+
[source,bash]
----
rpk topic describe <topic-name>
rpk topic alter-config <topic-name> --set replication.factor=<replication-factor>
----
+
A replication factor of 3 is recommended to ensure high availability and fault tolerance. With three replicas, the system can tolerate the failure of one broker without losing data or availability. This setup allows for one replica to be down for maintenance or due to failure, while still having two replicas available to serve read and write requests. This redundancy is crucial for maintaining the health and reliability of the cluster.

. Create a new node pool with the same number of nodes as your current pool.
+
If you only have 3 brokers, add an extra one (buffer broker).
+
:note-caption: Why add an extra node?
[NOTE]
====
The recommended topic replication factor is 3. This means each partition within a topic must have three replicas to maintain cluster health. To avoid making your cluster unhealthy, add a temporary broker before upgrading any of the three original nodes. This temporary broker is not needed if you have more brokers than your highest topic replication factor.
====
:note-caption: Note

. Configure tolerations, taints, and node selectors:
+
When updating your Redpanda resource or Helm values, you need to configure tolerations and node selectors so that the Pods are scheduled onto nodes in your new node pool. Below are the steps to determine the proper values for these settings and how to apply them.
+
--
.. Identify taints on your nodes
+
Taints prevent Pods from being scheduled on a node unless they have a matching toleration. To view the taints on a node, run:
+
[,bash]
----
kubectl describe node <node-name>
----
+
In the output, look for a section similar to:
+
[.no-copy]
----
Taints: redpanda-pool-new=true:NoSchedule
----
+
Here, the taint key is `redpanda-pool-new` and the effect is `NoSchedule`.

.. Identify or set node labels
+
Node selectors use labels to target specific nodes. List the labels on your nodes with:
+
[source,bash]
----
kubectl get nodes --show-labels
----
+
If your new node pool does not already have a specific label, add one by running:
+
[source,bash]
----
kubectl label nodes <node-name> nodetype=redpanda-pool-new
----
+
Now, the label `nodetype=redpanda-pool-new` can be used as the selector.

.. Update Your Redpanda resource or Helm values.
+
Replace the placeholders in the configuration with your actual values. For example:
+
[tabs]
======
Helm + Operator::
+
Patch your Redpanda resource with the following command:
+
[source,bash]
----
cat <<EOF > patch-nodepool.yaml
spec:
  clusterSpec:
    tolerations:
      - effect: NoSchedule
        key: <taint>   # Replace <taint> with your node taint key
        operator: Equal
        value: "true"
    nodeSelector:
      nodetype: <label>   # Replace <label> with your node label value
EOF
kubectl patch redpanda redpanda -n <namespace> --type merge --patch-file patch-nodepool.yaml
----

Helm::
+
Update your Helm values file with the following settings:
+
.`tolerations.yaml`
[source,yaml]
----
tolerations:
  - effect: NoSchedule
    key: <taint>   # Replace <taint> with your node taint key
    operator: Equal
    value: "true"
nodeSelector:
  nodetype: <label>   # Replace <label> with your node label value
----
+
Then run:
+
[source,bash]
----
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --values tolerations.yaml --reuse-values
----
======
--

. Set the update strategy for the StatefulSet to `OnDelete`.
+
This change ensures that broker Pods are only replaced when explicitly deleted, giving you manual control over the upgrade process.
+
[tabs]
======
Helm + Operator::
+
--
For example, patch your Redpanda resource to include:

[source,bash]
----
cat <<EOF > patch.yaml
spec:
  clusterSpec:
    statefulset:
      # replicas: 4
      updateStrategy:
        type: OnDelete
EOF
kubectl patch redpanda redpanda --namespace <namespace> --type merge --patch-file patch.yaml
----

NOTE: If you created a buffer node, uncomment the `statefulset.replicas` line to add a buffer broker to your cluster.
--

Helm::
+
--

Update your Helm values file to include:

.`statefulset.yaml`
[,yaml]
----
statefulset:
  # replicas: 4
  updateStrategy:
    type: OnDelete
----

NOTE: If you created a buffer node, uncomment the `statefulset.replicas` line to add a buffer broker to your cluster.

Then, run:

[,bash]
----
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --values statefulset.yaml --reuse-values
----

--
======

. Disable controllers:
+
[tabs]
======
Helm + Operator::
+
--

Scale down the operator to 0 to temporarily disable it:

```bash
kubectl scale deployment redpanda-operator --replicas=0 --namespace <namespace>
```

--
Helm::
+
--
If you enabled the NodeWatcher or Decommission controller in the Redpanda Helm chart:

[loweralpha]
Edit or remove the settings for the `controllers` sidecar in your Helm values overrides. For example, if you used a YAML values file:

.`controllers.yaml`
[,yaml]
----
statefulset:
  sideCars:
    controllers:
      enabled: false
      run: []
rbac:
  enabled: false
----

[,bash]
----
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --values controllers.yaml --reuse-values
----

--
======

. For each broker running on the old node pool, perform these steps:
+
--
.. Decommission the broker. This moves its data and replicas to other brokers.
+
[source,bash]
----
rpk redpanda admin brokers decommission <broker-id>
----
+
The time required depends on the amount of data being migrated from the broker's partitions. If the broker has a large amount of data, this process can take hours. For more details, see xref:manage:kubernetes/k-decommission-brokers.adoc[Decommission Brokers].

.. Delete the associated PVC:
+
For local PVs, delete the PVC to allow Kubernetes to provision new storage for the rescheduled broker.
+
[source,bash]
----
kubectl get pvc --namespace <namespace>
kubectl delete pvc <pvc-name> --namespace <namespace> --wait=false
----
+
NOTE: Deleting the PVC sets a deletion timestamp. The actual removal occurs when the Pod terminates. The `--wait=false` flag ensures the associated PersistentVolume is not deleted until the associated Pod is deleted so that the Redpanda broker can shut down cleanly.

.. Delete the Pod.
+
[source,bash]
----
kubectl get pods --namespace <namespace>
kubectl delete pod <pod-name> --namespace <namespace> --wait=false
----
+
This step ensures that the Pod is rescheduled onto the new node pool.

.. Check that this new Pod is running on your new node pool:
+
[source,bash]
----
kubectl get pods --namespace <namespace> -o wide | grep <pod-name>
----
+
If the Pod is not rescheduled, check the node's status and events for any issues.
+
[,bash]
----
kubectl describe node <node-name>
kubectl get events --namespace <namespace>
----

.. Verify cluster health:
+
[source,bash]
----
rpk cluster health
----

.. Repeat these steps for each broker sequentially.
--

. Revert the StatefulSet `updateStrategy` back to `RollingUpdate`:
+
[tabs]
======
Helm + Operator::
+
--
[source,bash]
----
cat <<EOF > patch-update-strategy.yaml
spec:
  clusterSpec:
    statefulset:
      updateStrategy:
        type: RollingUpdate
EOF
kubectl patch redpanda redpanda -n <namespace> --type merge --patch-file patch-update-strategy.yaml
----
--
Helm::
+
--
[source,bash]
----
cat <<EOF > statefulset.yaml
statefulset:
  updateStrategy:
    type: RollingUpdate
EOF
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace --values statefulset.yaml --reuse-values
----
--
======

. Scale the StatefulSet replica count back to the original number (removing the temporary buffer broker).

. If you disabled the controllers, re-enable them. For example:
+
[tabs]
======
Helm + Operator::
+
--

Scale up the operator to re-enable it:

```bash
kubectl scale deployment redpanda-operator --replicas=1 --namespace <namespace>
```

--
Helm::
+
--
.`controllers.yaml`
[,yaml]
----
statefulset:
  sideCars:
    controllers:
      enabled: true
      run:
        - "nodeWatcher"
        - "decommission"
----

[,bash]
----
helm upgrade --install redpanda redpanda/redpanda --namespace <namespace> --create-namespace \
  --values controllers.yaml --reuse-values
----
--
======

. Verify cluster health:
+
[source,bash]
----
rpk cluster health
----
+
Ensure all brokers are online and that data replication is healthy.

. Delete the old node pool according to your platform's best practices.

include::shared:partial$suggested-reading.adoc[]

* https://kubernetes.io/docs/concepts/workloads/pods/disruptions/[Kubernetes Pod Disruption Budgets^]
* https://helm.sh/docs/[Helm documentation^]
* xref:manage:kubernetes/k-decommission-brokers.adoc[Decommission Brokers]
* xref:reference:rpk/rpk-topic/rpk-topic-alter-config.adoc[rpk topic alter-config]
