= How Data Transforms Work
:description: Learn how Redpanda data transforms work.

Redpanda provides the framework to build and deploy inline transformations on data written to Redpanda topics, delivering processed and validated data to consumers in the format they expect. Redpanda does this directly inside the broker, eliminating the need to manage a separate stream processing environment or use 3rd-party tools. 

image::shared:wasm1.png[Data transforms in a broker] 

To learn how to build and deploy data transforms, see xref:./run-transforms.adoc[].

== WebAssemby in Redpanda

Data transforms use a WebAssembly (Wasm) engine inside a Redpanda broker, allowing Redpanda to control the entire transform lifecycle. For example, Redpanda can stop and start transforms when partitions are moved or to free up system resources for other tasks. 

Within Repdanda, there's a single Raft controller that manages cluster information, including data transforms. On every shard (core), Redpanda knows what data transforms exist in the cluster, as well as metadata about the transform, such as input and output topics and environment variables. 

Wasm is executed within a runtime in the broker. Data transforms take an input topic and map it to an output topic, running a virtual machine (VM) on the same shard as every partition leader for a topic. Redpanda uses just-in-time (JIT) compilation, which compiles the function in memory, writes it to executable space, then runs the directly translated machine code. When a shard becomes the leader of a given partition on the input topic, Redpanda does the following:

. Spins up a Wasm VM using the JIT-compiled WebAssembly module
. Pushes records from the input partition into the Wasm VM
. Writes the output, which may go to the same shard on the same machine, or to a different shard on the same machine, or to a different machine

image::shared:wasm_architecture.png[Wasm architecture in Redpanda]

The transform function processes every record produced to an input topic and returns zero or more records that are then produced to an output topic. Data transforms are applied to all partitions on an input topic. A record is processed after it has been successfully written to disk on the input topic. Because the transform happens in the background after the write finishes, the transform doesn't affect the original produced record and doesn't block writes to the input topic. 

image::shared:wasm_flow.png[Flow of record transform]

A new transform processes the input topic from the latest offset. Deployed transforms resume processing from the previous offset. 

Does a transform track its offset, like any other consumer?

It's managed by the broker. It's not a "normal" consumer group, but we'll have lag metrics exposed.

== Configure Wasm properties

When you deploy a data transform, Redpanda pushes the generated `.wasm` files and metadata to the cluster, which then stores and replicates the bytecode and metadata using internal broker topics. Each shard of Redpanda runs its own copy of the transform function. There is at most one runtime for a transform for any shard, and memory for each function is reserved within the broker. This is achieved with the following cluster configuration properties: 

- `wasm_per_core_memory_reservation`: Total amount of memory to reserve per shard 
- `wasm_per_function_memory_limit`: Limit for an individual transform's memory

At any moment, there may only be `wasm_per_core_memory_reservation`/ `wasm_per_function_memory_limit` transforms deployed to a cluster. CPU time is dynamically allocated to the Wasm runtime and ensures that the code does not run forever and cannot block the broker from handling traffic or doing other work, such as Tiered Storage uploads.

Set the properties based on how many functions you have and how much memory you anticipate needing. You want enough memory for your input record and output record to be in memory at the same time. For TinyGo, the overhead is 64KB. For standard Golang, the overhead is 16MB.

NOTE: These properties require the cluster to be restarted in order to be applied.

== Related topics

- xref:./run-transforms.adoc[]
- xref:reference:data-transform-api.adoc[]
- rpk transform **(link when we pull code include in Beta docs rpk section)**
