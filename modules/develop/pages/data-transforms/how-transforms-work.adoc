= How Data Transforms Work
:description: Learn how Redpanda data transforms work.

Redpanda provides the framework to build and deploy inline transformations (data transforms) on data written to Redpanda topics, delivering processed and validated data to consumers in the format they expect. Redpanda does this directly inside the broker, eliminating the need to manage a separate stream processing environment or use 3rd-party tools.

Data transforms let you run common data streaming tasks, like filtering, scrubbing, and transcoding, within Redpanda. For example, you may have consumers that require you to redact credit card numbers or convert JSON to Avro. Data transforms can also interact with the Redpanda Schema Registry to work with encoded data types.

image::shared:wasm1.png[Data transforms in a broker] 

To learn how to build and deploy data transforms, see xref:./run-transforms.adoc[].

== Data transforms with WebAssembly

Data transforms use https://webassembly.org/[WebAssembly^] (Wasm) engines inside a Redpanda broker, allowing Redpanda to control the entire transform lifecycle. For example, Redpanda can stop and start transforms when partitions are moved or to free up system resources for other tasks. 

Data transforms take an input topic and map it to an output topic, running a virtual machine (VM) on the same shard as every partition leader for a topic. Redpanda uses just-in-time (JIT) compilation, which compiles the function in memory, writes it to executable space, then runs the directly translated machine code. 

When you deploy a data transform, Redpanda pushes the generated `.wasm` files and metadata to the cluster, which then stores and replicates the bytecode and metadata using internal broker topics. Each shard of Redpanda runs its own copy of the transform function. There is at most one runtime for a transform for any shard, and memory for each function is reserved within the broker with the `wasm_per_core_memory_reservation` and `wasm_per_function_memory_limit` properties. CPU time is dynamically allocated to the Wasm runtime and ensures that the code does not run forever and cannot block the broker from handling traffic or doing other work, such as Tiered Storage uploads. 

== Flow of data transforms

When a shard becomes the leader of a given partition on the input topic of one or more active transforms, Redpanda does the following:

. Spins up a Wasm VM using the JIT-compiled Wasm module.
. Pushes records from the input partition into the Wasm VM.
. Writes the output. The output partition may exist on the same broker or on another broker in the cluster.

Within Repdanda, a single Raft controller manages cluster information, including data transforms. On every shard, Redpanda knows what data transforms exist in the cluster, as well as metadata about the transform function, such as input and output topics and environment variables. 

image::shared:wasm_architecture.png[Wasm architecture in Redpanda]

Each transform function reads from a specified input topic and writes to a specified output topic. The transform function processes every record produced to an input topic and returns zero or more records that are then produced to the specified output topic. Data transforms are applied to all partitions on an input topic. A record is processed after it has been successfully written to disk on the input topic. Because the transform happens in the background after the write finishes, the transform doesn't affect the original produced record, doesn't block writes to the input topic, and doesn't block produce and consume requests.

A new data transform reads the input topic from the latest offset. That is, it only reads new data produced to the input topic: it does not read records produced to the input topic before the transform was deployed. If a partition leader moves from one broker to another, then the data transform instance assigned to that partition moves with it.

When a partition replica loses leadership, the broker hosting that partition replica stops the transform instance running on the same shard. The broker that is now hosting the partition's new leader starts the transform on the same shard as that leader, and the transform resumes from the last committed offset.

If the previous transform instance failed to commit its latest offsets before moving with the partition leader (for example, if the broker crashed), then it's likely that the new transform instance will reprocess some events. For broker failures, transforms have at-least-once semantics, because records are retried from the committed last offset, and offsets are committed periodically. For more information, see xref:./run-transforms.adoc[].

== Suggested reading

- xref:reference:data-transform-api.adoc[]
- xref:reference:rpk/rpk-transform/rpk-transform.adoc[`rpk transform` commands] 
